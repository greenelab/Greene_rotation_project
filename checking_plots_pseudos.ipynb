{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the our code\n",
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "sys.path.insert(1, '../')\n",
    "from sc_preprocessing import sc_preprocess\n",
    "\n",
    "# general imports\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Requires the latest pip\n",
    "#pip install --upgrade pip\n",
    "\n",
    "# Current stable release for CPU and GPU\n",
    "#pip install tensorflow\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from collections import Counter\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "# programming stuff\n",
    "import time\n",
    "import os, sys\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of pseudobulks PER patient\n",
    "n_train = 1000\n",
    "\n",
    "### create the domains label \n",
    "\n",
    "# first for 10x data\n",
    "Label_full_10x = np.concatenate([np.full(n_train, 0), np.full(n_train, 1),\n",
    "                            np.full(n_train, 2), np.full(n_train, 3),\n",
    "                            np.full(n_train, 4), np.full(n_train, 5),\n",
    "                            np.full(n_train, 6), np.full(n_train, 7),\n",
    "                            np.full(n_train, 8), np.full(n_train, 9)], axis=0)\n",
    "label_full_10x = to_categorical(Label_full_10x)\n",
    "\n",
    "Label_perturb = np.concatenate([np.full(n_train, 1), np.full(n_train, 0),\n",
    "                            np.full(n_train, 0), np.full(n_train, 0),\n",
    "                            np.full(n_train, 0), np.full(n_train, 1),\n",
    "                            np.full(n_train, 1), np.full(n_train, 1),\n",
    "                            np.full(n_train, 0), np.full(n_train, 0)], axis=0)\n",
    "label_perturb = to_categorical(Label_perturb)\n",
    "\n",
    "\"\"\"\n",
    "# the 11th example is unlabeled is we train only\n",
    "# using 10x data\n",
    "unlabeled_10x_only_idx = 9\n",
    "\n",
    "# now for sm2 data\n",
    "Label_full_sm2 = np.concatenate([np.full(n_train, 0), np.full(n_train, 1), \n",
    "                                np.full(n_train, 2), np.full(n_train, 3),\n",
    "                                np.full(n_train, 4), np.full(n_train, 5)], axis=0)\n",
    "\n",
    "\n",
    "# when we train on 10x and sm2 we put them together\n",
    "Label_both = np.concatenate([Label_full_10x, Label_full_sm2+12])\n",
    "label_both = to_categorical(Label_both)\n",
    "\n",
    "# we append an additional binary value to indicate sm2 or 10x\n",
    "Label_both_dim = np.full(n_train*12, 0)\n",
    "Label_both_sm2_dim = np.full(n_train*6, 1)\n",
    "Label_both_dim = np.concatenate([Label_both_dim, Label_both_sm2_dim])\n",
    "Label_both_dim = to_categorical(Label_both_dim)\n",
    "\"\"\"\n",
    "label_full_10x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ivicha/Documents/VSCode/../../data/single_cell_data/augmented_pbmc_data/pbmc6k-mono_prop_0.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m gene_df_train\n\u001b[1;32m     13\u001b[0m exp_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpbmc6k-mono\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m pbmc6k_X, pbmc6k_Y, pbmc6k_gene_df \u001b[39m=\u001b[39m sc_preprocess\u001b[39m.\u001b[39;49mread_all_diva_files(data_path, \u001b[39mrange\u001b[39;49m(\u001b[39m10\u001b[39;49m), exp_id)\n\u001b[1;32m     15\u001b[0m pbmc6k_X\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m pbmc6k_gene_df\n\u001b[1;32m     18\u001b[0m lab_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpbmc6k-mono\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/VSCode/sc_preprocessing/sc_preprocess.py:190\u001b[0m, in \u001b[0;36mread_all_diva_files\u001b[0;34m(data_path, idx_range, file_name)\u001b[0m\n\u001b[1;32m    187\u001b[0m X_concat \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m idx_range:\n\u001b[0;32m--> 190\u001b[0m     X_train, Y_train, gene_df, _ \u001b[39m=\u001b[39m read_diva_files(data_path, idx, file_name)\n\u001b[1;32m    191\u001b[0m     X_train\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m gene_df\n\u001b[1;32m    193\u001b[0m     \u001b[39mif\u001b[39;00m X_concat \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/VSCode/sc_preprocessing/sc_preprocess.py:178\u001b[0m, in \u001b[0;36mread_diva_files\u001b[0;34m(data_path, file_idx, file_name, use_test)\u001b[0m\n\u001b[1;32m    175\u001b[0m gene_path \u001b[39m=\u001b[39m Path(pbmc_rep1_gene_file)\n\u001b[1;32m    176\u001b[0m sig_path \u001b[39m=\u001b[39m Path(pbmc_rep1_sig_file)\n\u001b[0;32m--> 178\u001b[0m prop_df \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload( \u001b[39mopen\u001b[39;49m( prop_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m ) )\n\u001b[1;32m    179\u001b[0m pseudobulks_df \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload( \u001b[39mopen\u001b[39m( pseudobulk_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m ) )\n\u001b[1;32m    180\u001b[0m gene_df \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload( \u001b[39mopen\u001b[39m( gene_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m ) )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ivicha/Documents/VSCode/../../data/single_cell_data/augmented_pbmc_data/pbmc6k-mono_prop_0.pkl'"
     ]
    }
   ],
   "source": [
    "res_path = f\"{os.getcwd()}/../../results/single_cell_data/diva_pbmc/\"\n",
    "bp_res_path = f\"{os.getcwd()}/../../results/single_cell_data/bp_pbmc/\"\n",
    "cs_res_path = f\"{os.getcwd()}/../../results/single_cell_data/cibersort_pbmc/\"\n",
    "data_path = f\"{os.getcwd()}/../../data/single_cell_data/augmented_pbmc_data/\"\n",
    "\n",
    "\n",
    "aug_data_path = \"/beevol/home/ivicha/Rotation_project/augmented_data\"\n",
    "\n",
    "cybersort_path = \"/beevol/home/ivicha/Rotation_project/cibersort\"\n",
    "\n",
    "data_path = \"/beevol/home/ivicha/Rotation_project/raw_matrix/matrix.csv\"\n",
    "\n",
    "scpred_path = \"/beevol/home/ivicha/Rotation_project/meta_data/meta.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_gene_file(res_path, exp_id):\n",
    "    gene_file = os.path.join(res_path, f\"train-{exp_id}-DIVA_features.pkl\")\n",
    "    gene_path = Path(gene_file)\n",
    "    gene_df_train = pickle.load( open( gene_path, \"rb\" ) )\n",
    "    return gene_df_train\n",
    "\n",
    "\n",
    "exp_id = \"pbmc6k-mono\"\n",
    "pbmc6k_X, pbmc6k_Y, pbmc6k_gene_df = sc_preprocess.read_all_diva_files(data_path, range(10), exp_id)\n",
    "pbmc6k_X.columns = pbmc6k_gene_df\n",
    "\n",
    "\n",
    "lab_id = \"pbmc6k-mono\"\n",
    "unlab_id = \"pbmc6k-mono\"\n",
    "pbmc6k_enc = tf.keras.models.load_model(f\"{res_path}/{lab_id}_{unlab_id}_encoder\")\n",
    "pbmc6k_train = read_gene_file(res_path, f\"{lab_id}-{unlab_id}\")\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "exp_id = \"pbmc_rep2_10xV2\"\n",
    "pbmc_rep2_10xV2_X, pbmc_rep2_10xV2_Y, pbmc_rep2_10xV2_gene_df = sc_preprocess.read_all_diva_files(data_path, range(10), exp_id)\n",
    "pbmc_rep2_10xV2_X.columns = pbmc_rep2_10xV2_gene_df\n",
    "\n",
    "\n",
    "exp_id = \"pbmc_rep2_sm2\"\n",
    "pbmc_rep2_sm2_X, pbmc_rep2_sm2_Y, pbmc_rep2_sm2_gene_df = sc_preprocess.read_all_diva_files(data_path, range(6), exp_id)\n",
    "pbmc_rep2_sm2_X.columns = pbmc_rep2_sm2_gene_df[\"gene_ids\"]\n",
    "\n",
    "\n",
    "exp_id = \"pbmc_rep1_sm2\"\n",
    "pbmc_rep1_sm2_X, pbmc_rep1_sm2_Y, pbmc_rep1_sm2_gene_df = sc_preprocess.read_all_diva_files(data_path, range(6), exp_id)\n",
    "pbmc_rep1_sm2_X.columns = pbmc_rep1_sm2_gene_df[\"gene_ids\"]\n",
    "\n",
    "\n",
    "exp_id = \"pbmc_rep2_10xV2_sm2_cells\"\n",
    "pbmc_rep2_10xV2_sm2_cells_X, pbmc_rep2_10xV2_sm2_cells_Y, pbmc_rep2_10xV2_sm2_cells_gene_df = sc_preprocess.read_all_diva_files(data_path, range(12), exp_id)\n",
    "pbmc_rep2_10xV2_sm2_cells_X.columns = pbmc_rep2_10xV2_sm2_cells_gene_df[\"gene_ids\"]\n",
    "\n",
    "\n",
    "lab_id = \"pbmc_rep2_10xV2_sm2_cells\"\n",
    "unlab_id = \"pbmc_rep2_sm2\"\n",
    "pbmc_rep2_sm2_enc = tf.keras.models.load_model(f\"{res_path}/{lab_id}_{unlab_id}_encoder\")\n",
    "pbmc_rep2_sm2_train = read_gene_file(res_path, f\"{lab_id}-{unlab_id}\")\n",
    "\n",
    "lab_id = \"pbmc_rep2_10xV2_sm2_cells\"\n",
    "unlab_id = \"pbmc_rep2_10xV2_sm2_cells\"\n",
    "pbmc_rep2_10xV2_sm2_cells_enc = tf.keras.models.load_model(f\"{res_path}/{lab_id}_{unlab_id}_encoder\")\n",
    "pbmc_rep2_10xV2_sm2_cells_train = read_gene_file(res_path, f\"{lab_id}-{unlab_id}\")\n",
    "\n",
    " \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc8dbb79165c794cee01247d49fade74906f1b66479a9f9c741c9322691d3980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
